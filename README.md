## Documentation-of-all-my-work-during-the-Stage-8-for-HNG-11

### Key Contributions

#### 1. I implemented the GitHub Actions to automate the testing process. The action is triggered every 15 minutes and on manual dispatch to run a series of API tests, ensuring that the status page is always up-to-date with the latest results.

The workflow was implemented for both the main project and the boilerplate, ensuring consistency across different environments.

Below is a sample of the workflow I implemented for the main project (aiforhomework):
```
name: API Status Check

on:
  schedule:
    - cron: '*/15 * * * *'
  workflow_dispatch:

jobs:
  run-api-tests:
    runs-on: be_runner
    steps:
      - uses: actions/checkout@v3

      - uses: SimonScholz/postman-newman-action@main
        with:
          collection: postman_collection.json
          reporters: "cli,json"
          outputOriginalSummary: true
        continue-on-error: true     

      - name: Send results to API
        run: |
          json_file=$(ls newman/*.json | head -n 1)
          curl -X POST https://${{ vars.STAGING_API_URL }}/api/v1/api-status \
            -H "Content-Type: application/json" \
            --data-binary @$json_file
```

This workflow:
- Checks out the code using the actions/checkout@v3 action.
- Runs the Postman tests using the SimonScholz/postman-newman-action@main, outputting the results in both CLI and JSON formats.
- Sends the test results to the API endpoint using a curl command, ensuring that the status data is up-to-date.
  
#### 2. Collaboration with QA Testers:

- I worked closely with the QA testers **(Idowu, Fatimah and Hafizah)** to integrate their Postman collections into the actions. Their test cases focused on API availability, response time, and data integrity, which were crucial for accurate status reporting.
- I ensured that the result.json file generated by the tests was correctly included all necessary data for backend processing.

#### 3. Backend Integration:

- I collaborated with the backend team to ensure that the test results were successfully received and processed by the API endpoint. This involved coordinating the parsing and storage of test results in the database.

#### 4. Frontend Coordination:

- I worked with the frontend team to ensure that the status page was live and accessible. I provided them with the necessary endpoints and data structure to display the API health status accurately.

### Challenges Faced and Solutions
#### 1. Newman Installation Issues:

- Challenge: Initially, I encountered difficulties with installing and using Newman directly in the CI/CD pipeline. The root cause seemed to be related to our use of Yarn instead of npm, which may have caused compatibility issues.

- Solution: To overcome this, I conducted research to find a suitable GitHub Action that could handle Newman execution without the need for direct installation. I discovered and integrated the SimonScholz/postman-newman-action@main, which seamlessly fit into our workflow and allowed us to run the Postman collections effectively.

#### 2. Large results.json File Size:

- Challenge: The results.json file generated by Newman was substantial, containing approximately 18,000 lines of data. When this large payload was sent to the API endpoint, it triggered an error related to exceeding the maximum request size.

- Solution: To resolve this, I adjusted the Nginx configuration by setting the client_max_body_size directive to 10MB, allowing larger payloads to be processed. Additionally, I collaborated with the backend team, instructing them to make similar adjustments in the Express application that handles the endpoint, ensuring it could accept the larger request size without issues.
